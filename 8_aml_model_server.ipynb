{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook we will perform inference wheater embeddings vector represents subgraph of normal or  anomalous transaction. using our anomaly detection model     \n",
    "---\n",
    "**NOTE**: \n",
    "\n",
    "In real life scenarios financial transaction are dynamically evolving graphs. Performing anomaly detection inference on graph embeddings in live Transaction Monitoring Systems will require 1st to update the graph and node representations after new transactions arrive. Recomputing entire graph for every newly arrived transaction will lead to unaxeptable delayes and even monitoring system failure. This problem  will be more sever if large amount of updates happen in a short time window.\n",
    "\n",
    "Contact us at Logical Clocks and we will help you to setup end to end graph based deep anomaly detection live Transaction Monitoring Systems. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>34</td><td>application_1612198280619_0004</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://resourcemanager.service.consul:8088/proxy/application_1612198280619_0004/\">Link</a></td><td><a target=\"_blank\" href=\"http://davitamlgpu-worker-1.internal.cloudapp.net:8042/node/containerlogs/container_e08_1612198280619_0004_01_000001/amlsim__meb10179\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "<pyspark.sql.session.SparkSession object at 0x7f0573e34f50>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from hops import model\n",
    "from hops.model import Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Model Repository for best anomaly detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME=\"ganAml\"\n",
    "EVALUATION_METRIC=\"loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model.get_best_model(MODEL_NAME, EVALUATION_METRIC, Metric.MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: ganAml\n",
      "Model version: 1\n",
      "{'loss': '0.00033020367845892906'}"
     ]
    }
   ],
   "source": [
    "print('Model name: ' + best_model['name'])\n",
    "print('Model version: ' + str(best_model['version']))\n",
    "print(best_model['metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model Serving of Exported Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hops import serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ganAml'"
     ]
    }
   ],
   "source": [
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    }
   ],
   "source": [
    "best_model['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/Models/ganAml'"
     ]
    }
   ],
   "source": [
    "model_path=\"/Models/\" + best_model['name']\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Could not create or update serving (url: /hopsworks-api/api/project/119/serving/), server response: \n",
      " HTTP code: 422, HTTP reason: UNPROCESSABLE_ENTITY, error code: 120001, error msg: An argument was not provided or it was malformed., user msg: The model path does not respect the TensorFlow standard\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/hops/serving.py\", line 193, in create_or_update\n",
      "    topic_name, num_partitions, num_replicas, serving_id, instances)\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/hops/serving.py\", line 304, in _create_or_update_serving_rest\n",
      "    error_code, error_msg, user_msg))\n",
      "hops.exceptions.RestAPIError: Could not create or update serving (url: /hopsworks-api/api/project/119/serving/), server response: \n",
      " HTTP code: 422, HTTP reason: UNPROCESSABLE_ENTITY, error code: 120001, error msg: An argument was not provided or it was malformed., user msg: The model path does not respect the TensorFlow standard\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create serving\n",
    "model_path=\"/Models/\" + best_model['name']\n",
    "model_path\n",
    "response = serving.create_or_update(artifact_path=model_path, serving_name=MODEL_NAME, serving_type=\"TENSORFLOW\", \n",
    "                                 model_version=best_model['version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available servings in the project\n",
    "for s in serving.get_all():\n",
    "    print(s.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "No serving with name: ganAml could be found among the list of available servings: \n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/hops/serving.py\", line 425, in get_status\n",
      "    serving = _find_serving_with_name(serving_name, servings)\n",
      "  File \"/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/hops/serving.py\", line 466, in _find_serving_with_name\n",
      "    \"available servings: {}\".format(serving_name, serving_names_str))\n",
      "hops.serving.ServingNotFound: No serving with name: ganAml could be found among the list of available servings: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get serving status\n",
    "serving.get_status(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Model Serving Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting serving with name: ganAml...\n",
      "Serving with name: ganAml successfully started"
     ]
    }
   ],
   "source": [
    "if serving.get_status(MODEL_NAME) == 'Stopped':\n",
    "    serving.start(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while serving.get_status(MODEL_NAME) != \"Running\":\n",
    "    time.sleep(5) # Let the serving startup correctly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Prediction Requests to the Served Model using Hopsworks REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully."
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "# Create a connection\n",
    "connection = hsfs.connection()\n",
    "# Get the feature store handle for the project's feature store\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_td = fs.get_training_dataset(\"gan_eval_df\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|           embedding|\n",
      "+------+--------------------+\n",
      "|     1|[-0.8758349, 1.15...|\n",
      "|     1|[0.30752838, -0.1...|\n",
      "|     1|[-0.49007943, -0....|\n",
      "|     1|[-0.46613508, -0....|\n",
      "|     1|[-0.9974007, 0.32...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "eval_td.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_server(model_name, input):\n",
    "    data = {\"signature_name\": \"serving_default\", \"inputs\": [input]}\n",
    "    return serving.make_inference_request(model_name, data)['outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_df = eval_td.read()\\\n",
    "                   .rdd.map(lambda x: (x.target,model_server(MODEL_NAME, np.array(x.embedding).tolist()))).map(lambda f: (f[0],f[1][0]))\\\n",
    "                   .toDF().toDF(\"target\",\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|target|     score|\n",
      "+------+----------+\n",
      "|     1|8.52341175|\n",
      "|     1|4.68761492|\n",
      "|     1|5.79249573|\n",
      "|     1|5.91423655|\n",
      "|     1|7.08572435|\n",
      "|     1|2.45506454|\n",
      "|     1|3.70257711|\n",
      "|     1|4.33131218|\n",
      "|     1|8.08009243|\n",
      "|     1|7.95012951|\n",
      "|     1|6.53424883|\n",
      "|     1|8.20870209|\n",
      "|     1|6.20180655|\n",
      "|     1|7.03330612|\n",
      "|     1|6.28016472|\n",
      "|     1|   4.55949|\n",
      "|     1|5.02041245|\n",
      "|     1|5.51366901|\n",
      "|     1| 4.8042531|\n",
      "|     1|4.64139605|\n",
      "+------+----------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "scored_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
